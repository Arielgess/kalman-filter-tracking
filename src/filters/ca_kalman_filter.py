import numpy as np

from src.filters.base_kalman_filter import BaseKalmanFilter, InitializationData


class CAKalmanFilter(BaseKalmanFilter):
    """
    The state is [x, v_x, a_x y, v_y, a_y] in case of 2-D, and [x, v_x, a_x, y, v_y, a_y, z, v_z, a_z] in case of 3-D
    """

    def initialize(self, x0=None, P0=None):
        super().initialize(x0, P0)
        if self.initialization_data.observation_noise_std.shape != (self.dim,):
            raise ValueError("Observation noise is not in the correct dimensions")

        F, H, Q, R = self._get_motion_model_matrices(self.initialization_data)
        self.kf.F = F
        self.kf.H = H
        self.kf.Q = Q
        self.kf.R = R

    def _get_x0_from_measurements(self, measurements: np.ndarray) -> np.ndarray:
        estimated_v0 = (measurements[1] - measurements[0]) / self.dt
        if self.dim == 2:
            # this means that x0 should be of the form [x, v_x, a_x y, v_y, a_y]
            x0 = np.array([measurements[0,0], estimated_v0[0], 0, measurements[0,1], estimated_v0[1], 0])
        else:
            # then dim==3, so x0 should be of the form [x, v_x, a_x y, v_y, a_y, z, v_z a_z]
            x0 = np.array([measurements[0,0], estimated_v0[0], 0,
                           measurements[0,1], estimated_v0[1], 0,
                           measurements[0,2], estimated_v0[2], 0])
        return x0

    def _get_P0_from_measurements(self, measurements: np.ndarray) -> np.ndarray:
        return np.eye(self.dim * 3) * 1e1

    def _project_Q(self, Q):
        """
        This method was generated by ChatGPT, it keeps Q as the form fits for CA with white jerk
        :param q_bounds:
        :param tie_axes:
        :return:
        """
        q_bounds = (1e-10, 1e+1)
        tie_axes = True

        Q = 0.5 * Q + Q.T  # making Q to be symmetric (which could not be the case due to noise)
        n = 3 * self.dim_measurement
        dt = self.dt  # store dt in the class

        # B is the theoretical form of Q that we expect (without the scalar multiply)
        B = np.array([[dt ** 5 / 20, dt ** 4 / 8, dt ** 3 / 6],
                      [dt ** 4 / 8, dt ** 3 / 3, dt ** 2 / 2],
                      [dt ** 3 / 6, dt ** 2 / 2, dt]], float)
        bb = B.reshape(-1)
        denom = float(bb @ bb)  # <B,B> with element-wise multiplication

        Qp = np.zeros((n, n), float)
        qs = []
        for a in range(self.dim_measurement):
            # extract the Q_axis block
            i = 3 * a
            Qa = Q[i:i + 3, i:i + 3]
            # find the best approximation for q_hat s.t Q_axis = qB (Q_axis is the empirical one, qB is based on the theoretical structure)
            q_hat = float((Qa.reshape(-1) @ bb) / denom)  # LS fit onto B
            q_hat = float(np.clip(q_hat, *q_bounds))
            qs.append(q_hat)
            Qp[i:i + 3, i:i + 3] = q_hat * B

        if tie_axes:
            q_med = float(np.clip(np.median(qs), *q_bounds))
            for a in range(self.dim_measurements):
                Qp[3 * a:3 * a + 3, 3 * a:3 * a + 3] = q_med * B
        return Qp


    def _get_motion_model_matrices(self, initialization_data: InitializationData):
        dt = self.dt
        F1 = np.array([[1, dt, 0.5 * dt * dt],
                       [0, 1, dt],
                       [0, 0, 1]], float)
        Z = np.zeros((3, 3))
        Q_axis = initialization_data.white_accel_density * \
                 np.array([
                     [dt ** 5 / 20, dt ** 4 / 8, dt ** 3 / 6],
                     [dt ** 4 / 8, dt ** 3 / 3, dt ** 2 / 2],
                     [dt ** 3 / 6, dt ** 2 / 2, dt]
                 ])

        if self.dim == 2:
            F = np.block([
                [F1, Z],
                [Z, F1]
            ])

            H = np.array([
                [1, 0, 0, 0, 0, 0],  # measure x
                [0, 0, 0, 1, 0, 0],  # measure y
            ])

            Q = np.block([
                [Q_axis, Z],
                [Z, Q_axis]
            ])

        else:
            F = np.block([
                [F1, Z, Z],
                [Z, F1, Z],
                [Z, Z, F1]
            ])

            H = np.array([
                [1, 0, 0, 0, 0, 0, 0, 0, 0],  # x
                [0, 0, 0, 1, 0, 0, 0, 0, 0],  # y
                [0, 0, 0, 0, 0, 0, 1, 0, 0],  # z
            ], dtype=float)

            Q = np.block([[Q_axis, Z, Z],
                          [Z, Q_axis, Z],
                          [Z, Z, Q_axis]])

        R = np.diag(initialization_data.observation_noise_std ** 2)
        return F, H, Q, R
